{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b009cc2-d6ba-4481-8112-9622b6d88119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f2eda4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8951969",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter = Counter();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d533789",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../archive/Reviews.csv\";\n",
    "\n",
    "df = pd.read_csv(file);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cfe02bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568449</th>\n",
       "      <td>568450</td>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A28KG5XORO54AY</td>\n",
       "      <td>Lettie D. Carter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1299628800</td>\n",
       "      <td>Will not do without</td>\n",
       "      <td>Great for sesame chicken..this is a good if no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>568451</td>\n",
       "      <td>B003S1WTCU</td>\n",
       "      <td>A3I8AFVPEE8KI5</td>\n",
       "      <td>R. Sawyer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1331251200</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>568452</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A121AA1GQV751Z</td>\n",
       "      <td>pksd \"pk_007\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1329782400</td>\n",
       "      <td>Perfect for our maltipoo</td>\n",
       "      <td>These stars are small, so you can give 10-15 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>568453</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A3IBEVCTXKNOH</td>\n",
       "      <td>Kathy A. Welch \"katwel\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1331596800</td>\n",
       "      <td>Favorite Training and reward treat</td>\n",
       "      <td>These are the BEST treats for training and rew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>568454</td>\n",
       "      <td>B001LR2CU2</td>\n",
       "      <td>A3LGQPJCZVL9UC</td>\n",
       "      <td>srfell17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1338422400</td>\n",
       "      <td>Great Honey</td>\n",
       "      <td>I am very satisfied ,product is as advertised,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568454 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId                      ProfileName  \\\n",
       "0            1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1            2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2            3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3            4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4            5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "...        ...         ...             ...                              ...   \n",
       "568449  568450  B001EO7N10  A28KG5XORO54AY                 Lettie D. Carter   \n",
       "568450  568451  B003S1WTCU  A3I8AFVPEE8KI5                        R. Sawyer   \n",
       "568451  568452  B004I613EE  A121AA1GQV751Z                    pksd \"pk_007\"   \n",
       "568452  568453  B004I613EE   A3IBEVCTXKNOH          Kathy A. Welch \"katwel\"   \n",
       "568453  568454  B001LR2CU2  A3LGQPJCZVL9UC                         srfell17   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                          1                       1      5  1303862400   \n",
       "1                          0                       0      1  1346976000   \n",
       "2                          1                       1      4  1219017600   \n",
       "3                          3                       3      2  1307923200   \n",
       "4                          0                       0      5  1350777600   \n",
       "...                      ...                     ...    ...         ...   \n",
       "568449                     0                       0      5  1299628800   \n",
       "568450                     0                       0      2  1331251200   \n",
       "568451                     2                       2      5  1329782400   \n",
       "568452                     1                       1      5  1331596800   \n",
       "568453                     0                       0      5  1338422400   \n",
       "\n",
       "                                   Summary  \\\n",
       "0                    Good Quality Dog Food   \n",
       "1                        Not as Advertised   \n",
       "2                    \"Delight\" says it all   \n",
       "3                           Cough Medicine   \n",
       "4                              Great taffy   \n",
       "...                                    ...   \n",
       "568449                 Will not do without   \n",
       "568450                        disappointed   \n",
       "568451            Perfect for our maltipoo   \n",
       "568452  Favorite Training and reward treat   \n",
       "568453                         Great Honey   \n",
       "\n",
       "                                                     Text  \n",
       "0       I have bought several of the Vitality canned d...  \n",
       "1       Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2       This is a confection that has been around a fe...  \n",
       "3       If you are looking for the secret ingredient i...  \n",
       "4       Great taffy at a great price.  There was a wid...  \n",
       "...                                                   ...  \n",
       "568449  Great for sesame chicken..this is a good if no...  \n",
       "568450  I'm disappointed with the flavor. The chocolat...  \n",
       "568451  These stars are small, so you can give 10-15 o...  \n",
       "568452  These are the BEST treats for training and rew...  \n",
       "568453  I am very satisfied ,product is as advertised,...  \n",
       "\n",
       "[568454 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8104b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokenized\"] = df[\"Text\"].apply(word_tokenize);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3f8c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing and Numericalization\n",
    "word_counter = Counter()\n",
    "for tokens in df['tokenized']:\n",
    "    word_counter.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e4ce6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {word: idx + 2 for idx, (word, _) in enumerate(word_counter.most_common())}\n",
    "vocab['<PAD>'] = 0  # Padding token\n",
    "vocab['<UNK>'] = 1  # Unknown token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b563e3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['numericalized'] = df['tokenized'].apply(lambda x: [vocab.get(token, vocab['<UNK>']) for token in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dce5d77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "max_len = max(map(len, df['numericalized']))\n",
    "df['padded'] = df['numericalized'].apply(lambda x: x + [vocab['<PAD>']] * (max_len - len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f57c7ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super(CustomDataset, self).__init__();\n",
    "        self.X = X;\n",
    "        self.y = y;\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X);\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fb0a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Score'] = df['Score'] - 1\n",
    "# Load the data, padded versions.\n",
    "X = torch.tensor(df[\"padded\"].tolist());\n",
    "y = torch.tensor(df[\"Score\"].tolist()).long();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "397f7c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(X, y);\n",
    "n = len(dataset);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e70ac2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32;\n",
    "train_size = int(0.75 * n);\n",
    "validation_size = int(0.15 * n);\n",
    "test_size = n - train_size - validation_size;\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size, test_size])\n",
    "\n",
    "# Create DataLoader for each train, validation, and test datasets.\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ebf85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers = 1):\n",
    "        super(Model, self).__init__();\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim);\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True);\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim);\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x);\n",
    "        lstm_out, _ = self.lstm(embedded);\n",
    "        out = self.fc(lstm_out[:, -1, :]);\n",
    "        return out;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ade04947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyperparameters\n",
    "vocab_size = len(vocab);\n",
    "embedding_dim = 100;\n",
    "hidden_dim = 128;\n",
    "output_dim = 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9468a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(vocab_size, embedding_dim, hidden_dim, output_dim);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4105a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss();\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7b5dfcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels);\n\u001b[1;32m     18\u001b[0m \u001b[39m# Backward pass and optimization.\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m loss\u001b[39m.\u001b[39;49mbackward();\n\u001b[1;32m     20\u001b[0m optimizer\u001b[39m.\u001b[39mstep();\n\u001b[1;32m     22\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem();\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10;\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train(); # Train the model.\n",
    "    total_loss = 0; # Initialize the Loss to 0.\n",
    "\n",
    "    for inputs, labels in train_dataloader:\n",
    "        optimizer.zero_grad()  # Clearing out the Gradient Descent\n",
    "\n",
    "        # Forward the loss\n",
    "        inputs = inputs.to(torch.int64)\n",
    "        labels = labels.to(torch.int64)\n",
    "        outputs = model(inputs);\n",
    "\n",
    "        # Calculate the loss.\n",
    "        loss = criterion(outputs, labels);\n",
    "\n",
    "        # Backward pass and optimization.\n",
    "        loss.backward();\n",
    "        optimizer.step();\n",
    "\n",
    "        total_loss += loss.item();\n",
    "\n",
    "    # Print average loss for each epoch\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_dataloader)}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8214c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26518b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849a1e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a614f05e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b055ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset and obtain random sample from the dataset.\n",
    "n = len(df);\n",
    "\n",
    "# Generate and shuffle the indices.\n",
    "indices = np.arange(n);\n",
    "indices = np.random.permutation(indices);\n",
    "\n",
    "# Select the train, validation, and test indices. For this LSTM model, we choose to select 75%, 15%, and 10% segments of the dataset respectively.\n",
    "train_indices = indices[:int(0.7 * n)];\n",
    "val_indices = indices[int(0.7 * n):int(0.85 * n)];\n",
    "test_indices = indices[int(0.9*n):];\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(df[\"Text\"], train_indices);\n",
    "val_dataset = torch.utils.data.Subset(df[\"Text\"], val_indices);\n",
    "test_dataset = torch.utils.data.Subset(df[\"Text\"], test_indices);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "665bae10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x334951d80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7ad6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
